= Batch execution and jobs

Just like any financial system, Fineract also has batch jobs to achieve some processing on the data that's stored in the system.

The batch jobs in Fineract are implemented using https://docs.spring.io/spring-batch/docs/current/reference/html/[Spring Batch]. In addition to the Spring Batch ecosystem, the automatic scheduling is done by the http://www.quartz-scheduler.org/[Quartz Scheduler] but it's also possible to trigger batch jobs via regular APIs.

== Glossary

[cols="1,1"]
|===
|*Job*
|A Job is an object that encapsulates an entire batch process.

|*Step*
|A Step is an object that encapsulates an independent phase of a Job.

|*Chunk oriented processing*
|Chunk oriented processing refers to reading the data one at a time and creating 'chunks' that are written out within a transaction boundary.

|*Partitioning*
|Partitioning refers to the high-level idea of dividing your data into so called partitions and distributing the individual partitions among Workers. The splitting of data and pushing work to Workers is done by a Manager.

|*Remote partitioning*
|Remote partitioning is a specialized partitioning concept. It refers to the idea of distributing the partitions among multiple JVMs mainly by using a messaging middleware.

|*Manager node*
|The Manager node is one of the objects taking a huge part when using partitioning. The Manager node is responsible for dividing the dataset into partitions and keeping track of all the divided partitions' Worker execution. When all Workers nodes are done with their partitions, the Manager will mark the corresponding Job as completed.

|*Worker node*
|A Worker node is the other important party in the context of partitioning. The Worker node is the one executing the work needed for a single partition.

|===

== Batch jobs in Fineract
=== Types of jobs
The jobs in Fineract can be divided into 2 categories:

* Normal batch jobs
* Partitionable batch jobs

Most of the jobs are normal batch jobs with limited scalability because Fineract is still passing through the evolution on making most of them capable to process a high-volume of data.

=== List of jobs

[cols="1,1,1,1"]
|===
|*Job name*
|*Active by default*
|*Partitionable*
|*Description*

|LOAN_CLOSE_OF_BUSINESS
|No
|Yes
|TBD

|===

== Batch job execution
=== State management
State management for the batch jobs is done by the Spring Batch provided state management. The data model consists of the following database structure:

image::{imagesdir}/batch-jobs-state-management.png[]

The corresponding database migration scripts are shipped with the Spring Batch core module under the `org.springframework.batch.core` package. They are only available as native scripts and are named as `schema-*.sql` where `*` is the short name of the database platform. For MySQL it's called `schema-mysql.sql` and for PostgreSQL it's called `schema-postgresql.sql`.
When Fineract is started, the database dependent schema SQL script will be picked up according to the datasource configurations.

=== Chunk oriented processing

Chunking data has not been easier. Spring Batch does a really good job at providing this capability.

In order to save resources when starting/committing/rollbacking transactions for every single processed item, chunking shall be used. That way, it’s possible to mark the transaction boundaries for a single processed chunk instead of a single item processing. The image below describes the flow with a very simplistic example.

image::{imagesdir}/batch-jobs-chunking.png[]

In addition to not opening a lot of transactions, the processing could also benefit from JDBC batching. The last step - writing the result into the database - collects all the processed items and then writes it to the database; both for MySQL and PostgreSQL (the databases supported by Fineract) are capable of grouping multiple DML (INSERT/UPDATE/DELETE) statements and sending them in one round-trip, optimizing the data being sent over the network and granting the possibility to the underlying database engine to enhance the processing.

=== Remote partitioning
Spring Batch provides a really nice way to do remote partitioning. The 2 type of objects in this setup is a manager node - who splits and distributes the work - and a number of worker nodes - who picks up the work.

In remote partitioning, the worker instances are receiving the work via a messaging system as soon as the manager splits up the work into smaller pieces.

Remote partitioning could be done 2 ways in terms of keeping the job state up-to-date. The main difference between the two is how the manager is notified about partition completions.

One way is that they share the same database. When the worker does something to a partition - for example picks it up for processing - it updates the state of that partition in the database. In the meantime, the manager regularly polls the database until all partitions are processed. This is visualized in the below diagram.

image::{imagesdir}/batch-jobs-remote-partitioning.png[]

An alternative approach to this - when the database is not intended to be shared between manager and workers - is to use a messaging system (could be the same as for distributing the work) and the workers could send back a message to the manager instance, therefore notifying it about failure/completion. Then the manager can simply keep the database state up-to-date.

Even though the alternative solution decouples the workers even better, we thought it's not necessary to add the complexity of handling reply message channel to the manager.

Also, please note that the partitioned job execution is multitenant meaning that the workers will receive which tenant it should do the processing for.

==== Supported message channels

For remote partitioning, the following message channels are supported by Fineract:

* Any JMS compatible message channels (ActiveMQ, Amazon MQ, etc)

==== Fault-tolerance scenarios

There are multiple fault tolerance use-cases that this solution must and will support:

1. If the manager fails during partitioning
2. If the manager completes the partitioning and the partition messages are sent to the broker but while the manager is waiting for the workers to finish, the manager fails
3. If the manager runs properly and during a partition processing a worker instance fails

In case of scenario 1), the simple solution is to re-trigger the job via API or via the Quartz scheduler.

In case of scenario 2), there’s no out-of-the-box solution by Spring Batch. Although there's a custom mechanism in place that'll resume the job upon restarting the manager. There are 2 cases in the context of this scenario:

* If all the partitions have been successfully processed by workers
* If not all the partitions have been processed by the workers

In the first case, we'll simply mark the stuck job as `FAILED` along with it's partitioning step and instruct Spring Batch to restart the job. The behavior in this case will be that Spring Batch will spawn a new job execution but will notice that the partitions have all been completed so it's not going to execute them once more.

In the latter case, the same will happen as for the first one but before marking the job execution as `FAILED`, we'll wait until all partitions have been completed.

[plantuml, format=png]
....
@startuml
skinparam linetype ortho

(*) --> "Manager starts"
if "Is there a running job available?" then
  if "Are all partitions have been completed?" then
      -->[Yes] "Update job state to FAILED"
      --> "Restart the job"
      --> "Spring Batch\ntransitions the job\n state to COMPLETED"
      -right-> (*)
    else
      -->[No] "Wait until all partitions have been completed"
      -left-> "Update job state to FAILED"
endif
else
  -right>[No] (*)
endif

@enduml
....

In case of scenario 3), another worker instance will take over the partition since it hasn't been finished.

== Configurable batch jobs

There's another type of distinction on the batch jobs. Some of them are configurable in terms of their behavior.

The currently supported configurable batch jobs are the following:

* LOAN_CLOSE_OF_BUSINESS

The behavior of these batch jobs are configurable. There's a new terminology we're introducing called *business steps*.

=== Business steps

Business steps are a smaller unit of work than regular Spring Batch Steps and the two are not meant to be mixed up because there's a large difference between them.

A Spring Batch Step's main purpose is to decompose a bigger work into smaller ones and making sure that these smaller Steps are properly handled within a single database transaction.

In case of a business step, it's a smaller unit of work. Business steps live *within* a Spring Batch Step. Fundamentally, they are simple classes that are implementing an interface with a single method that contains the business logic.

Here's a very simple example:

[source]
----
public class MyCustomBusinessStep implements BusinessStep<Loan> {
    @Override
    public Loan process(Loan loan) {
        // do something
    }
}
----

[source]
----
public class LoanCOBItemProcessor implements ItemProcessor<Loan, Loan> {
    @Override
    public Loan process(Loan loan) {
        List<BusinessStep<Loan>> bSteps = getBusinessSteps();
        Loan result = loan;
        for (BusinessStep<Loan> bStep : bSteps) {
            result = bStep.process(result);
        }
        return result;
    }
}
----

=== Business step configuration

The business steps are configurable for certain jobs. The reason for that is because we want to allow the possibility for Fineract users to configure their very own business logic for generic jobs, like the Loan Close Of Business job where we want to do a formal "closing" of the loans at the end of the day.

All countries are different with a different set of regulations. However in terms of behavior, there's no all size fits all for loan closing.

For example in the United States of America, you might need the following logic for a day closing:

1. Close fully repaid loan accounts
2. Apply penalties
3. Invoke IRS API for regulatory purposes

While in Germany it should be:

1. Close fully repaid loan accounts
2. Apply penalties
3. Do some fraud detection on the account using an external service
4. Invoke local tax authority API for regulatory purposes

These are just examples, but you get the idea.

The business steps are configurable through APIs:

Retrieving the configuration for a job:

[source]
----
GET /fineract-provider/api/v1/jobs/{jobName}/steps?tenantIdentifier={tenantId}
HTTP 200

{
  "jobName": "LOAN_CLOSE_OF_BUSINESS",
  "businessSteps": [
    {
      "stepName": "APPLY_PENALTY_FOR_OVERDUE_LOANS",
      "order": 1
    },
    {
      "stepName": "LOAN_TAGGING",
      "order": 2
    }
  ]
}
----

Updating the business step configuration for a job:

[source]
----
PUT /fineract-provider/api/v1/jobs/{jobName}/steps?tenantIdentifier={tenantId}

{
  "businessSteps": [
    {
      "stepName": "LOAN_TAGGING",
      "order": 1
    },
    {
      "stepName": "APPLY_PENALTY_FOR_OVERDUE_LOANS",
      "order": 2
    }
  ]
}
----

The business step configuration for jobs are tracked within the database in the `m_batch_business_steps` table.

== Fineract COB Performance Improvements with Spring Batch

Fineract's COB is not distributed.

=== Background

The current COB is single threaded. This is now, solved bu integrating Spring Batch and distributing the work. Fineract jobs generally do not have direct dependencies on each other. Fineract has a library of jobs that can be used. Jobs need to be run in a particular order to achieve the desired result. List of batch jobs include **managing scheduler jobs**.

By using Scheduler Jobs, you can set batch jobs to be completed at regular intervals. Users can schedule, modify or delete jobs. Users can  manually run selected jobs by accessing the list of Scheduler Jobs. Scheduler jobs include:

.Scheduler Jobs
|===
^| Job Name ^| Purpose/Description ^| Scheduled Frequency for Execution
| Add Accrual Transactions | All the interest will be accrued till the 'Due date' of the job run and can be viewed under 'Transactions' tab (Uncheck 'Hide Accruals') | Daily
| Update Savings Dormant Accounts | If dormant account definition is, let's say 6 months during  which no transactions (deposit or withdrawal) are done on savings account, This job updates all such savings accounts to 'Dormant state'.  | Daily
| Recalculate Interest For Loans | If loan accounts enabled with Interest Recalculation and if the clients make more repayment, the new interest will be automatically calculated. On the other hand, if the client makes less repayment or late repayment, this job is run to update the repayment schedule. | Daily
| Apply Holidays to Loans |If new 'future' holiday is created (say, February 1) and if this job is ran successfully (say on January 15), it should affect all the repayments scheduled on February 1 and must be postponed to the date described by holiday definition. bAdd Periodic Accrual Transactions. | Daily
| Transfer Interest to Savings | If this job is run successfully, the interest from, let's say, FDs or RDs can be transferred to Savings account. The FD or RD account must be pre-configured with Savings account | Monthly
| Apply Annual Fee for Savings | It applies recurrent fee- that is annual fee for all savings accounts of the clients which are attached with annual fee. You can create annual fee (or any other recurrent fee like monthly fee) for savings account in Admin>Products>Charges and later add it either directly to savings product or at the time of submission of savings application. | Daily
| Pay Due Savings Charges | Savings account can have 'Specified Due Date' charge. And if this job is run, all the due date charges prior to the job run date will be applied and the charge amount will be deducted from the savings account. | Daily
| Add Periodic Accrual Transactions | Similar to 'Add Accrual Transactions' except that all the interest will be accrued till the current date (i.e... Job run date and time) | Daily
| Add Accrual Transactions For Loans With Income Posted As Transactions | Similar to 'Add Accrual Transactions', except that Compounded interest will be accrued once this job is ran. In other words, this job should be run if compounded interests have to accrued. | Daily
| Transfer fee for Loans from Savings | Some loans could have 'Installment Fee' (or due date fee) and some amount as a fee will be charged from savings account and paid for loan account. If this job is run, Fees will be transferred from savings account and will be paid for loan account if loan account is linked with savings account and Fee transfer is configured. | Daily
| Execute standing instruction | Standing instructions are created in client level whenever - For Example, A Client has one savings account and one loan account and let's say he has loan repayment first of every month and he expects that the repayments of his loan account must be done through deducting from his savings account on the first of every month automatically.

Once this job is ran successfully, standing instruction of all clients for the particular date (i.e .. job run date) will be applied. That is, as given in the example above, if standing instruction is ran on the first of every month, the savings account will be debited and the loan account will be credited with repayment. | Daily
| Update Loan Paid in Advance | The loan paid in advance immediately updates after the transaction in which loan repayment is done prior to scheduled date. This job is no longer required. | -
| Get Delivery Reports from SMS Gateway | This job is run to get delivery reports from SMS gateway in order to check how many SMSs are successfully delivered.  | Daily/Manually
| Execute Report Mailing Jobs | This job is run to mail the reports regularly or recurrently to the given mail ids. It has no UI and mail ids and reports are configured in database level. | Daily/Weekly/Monthly
| Post Dividend for Shares | This job is run to post dividends of shares to linked savings account. It can be run monthly/quarterly/half-yearly in order to post dividend to savings account. | Daily/Weekly/Monthly
| Post Interest for Savings | This job is run to post interest to savings account. It can be run monthly/quarterly/half-yearly in order to post interest to savings account. Interest could be based on 'Average Daily Balance' of Savings Account or 'Daily Balance' of the savings account. | Monthly
| Update Email Outbound with campaign message |This job is run to send all emails from email server to customer mail account.  | Daily
| Update SMS Outbound with Campaign Message | This job is run to send all messages from 'Message Gateway' server to customer mobile premises.  | Daily
| Send Messages to SMS Gateway | This job is run to send SMSs  from platform to 'Message-Gateway' server.  | Daily/Manually
| Execute  Email | This job is run to send  Emails (without reports) with given template email formats.  | Daily/Weekly/Monthly
| Update Deposit Accounts Maturity details | This job is specifically for Fixed Deposits and Recurring Deposits. Once this job is ran, all the FDs, RDs which are in 'ready for maturity state' will be matured and could be closed by: Withdrawing the matured amount, Transferring the matured amount to Savings, Reinvesting matured amount for next fixed period (in case of RDs) | Monthly
| Apply penalty to overdue loans |  This job once ran successfully applies penalty to all overdue loans   based on the penalty definition. The penalties could be daily, weekly  or monthly based penalty charge definition.  | Daily
| Update Accounting Running Balances | This job once ran successfully, updates all the running balances based on the branch (office) level.  | Monthly
| Update Loan Arrears Ageing | This job updates all the loan accounts into 'Arrears Stage' based on Arrears definition of the loan accounts. The loan accounts could have different arrears ageing based on the definition (It's generally defined in loan product level). | Daily
| Update non-Performing Assets | This job updates loan accounts to 'NPA' based on NPA definition in the loan product. Generally, first loans move into arrears and arrears ageing exceeds certain limit, they move into NPA based on the definition.  | Daily
| Update Loan Summary | This job updates loan summary of each loan account of the clients. However this job is no longer required as loan summary is updated instantly after each transaction. | -
| Generate Loan Loss Provisioning | This job updates provisioning entries (Accounting>Provisioning Entries) with type (Standard, Sub Standard, etc) defined by Loan Provisioning Criteria (Admin>Organization) | Frequency will be defined by the organization.
| Generate Adhoc Client Schedule | |
| Generate Mandatory Savings Schedule | |
|===

=== Engineering Implementation

Now, Fineract has distributed COB integrated with Spring Batch. It splits the accounts that need to be processed into chunks. It then load the chunks into a queue. Further, it distributes the processsing of chunks across a EKS Pod that is dedicated to the COB. This makes the number of accounts per chunk configurable. Each chunk runs in a single database transaction. Each chunks is processed by each job in the COB pipeline in serial.

== Fineract COB Availability Enhancements with Spring Batch

Users and customers expects partner SORs to be online 24*7/365 in read/write mode.

=== Background

Fineract doest not had support for account state changes via the REST API while the account is being processed by the COB batch system. Fineract did not previosly support write operation for the next business day during COB for the previous business day.

=== Engineering Implementation

Now, with async writes Fineract further enhances performance with Spring Batch. It places the writes in a queue for the chunk and return a 202 accepted. When chunk completes to process the queue, an async API is impossible to adapat to the Partner API and is a breaking change to Fineract's API.

It also rejects writes, doing the right thing at the right moment. If the account is being processed in a chunk then it rejects the write. This is easier to adapater to the Partner API then async writes. This is used if the write operation thread times out while waiting for the chunk to be processed because the COB couldn't be inlined. With this, on API write operation:

If COB is in-progress and the account is not processed then, it locks account, runs COB for the account, exectues write operation on account and then unloacks account.

If account is processed, it performs writes as normal. If in case, account is locked, it waits for the chunk to finish.

This is performed for all accounts once the COB date changes.

The job with write operations is done withing 30 seconds. 
